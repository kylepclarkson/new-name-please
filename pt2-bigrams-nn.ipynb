{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0705e97d-6485-4c5b-abff-4f31e138f99f",
   "metadata": {},
   "source": [
    "## Bigrams using neural networks\n",
    "\n",
    "In the previous notebook we implemented a bigram model to generate names using a dataset of US first names. \n",
    "By counting the occurrences of all bigrams within the dataset, we created a probability distribution for each.\n",
    "We analysed the output of the model and defined the negative log-likelihood (NLL) of our model which allowed us a way to quantify just how well our model performed. \n",
    "\n",
    "Similar to the previous notebook, in this one we'll implement a bigram model on the same dataset. However instead of using the occurrence counts to compute the probabilities, we'll use a neural network, our NLL function, and back propagation to *learn* the probabilities. \n",
    "While we'll see the neural network doesn't before better than the occurrence count model, it will be more generalizable and provide foundations for more complex models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7da967-1520-4194-aded-9f2c0d40c23b",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "Let's revisit some code from the previous notebook to build the dataset and helper objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcde81a-1f0d-412e-93e2-d58d5e74d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "fp = \"../.data/nlp/\"\n",
    "train_set = open(f'{fp}training_corpus.txt', 'r').read().splitlines()\n",
    "valid_set = open(f'{fp}validation_corpus.txt', 'r').read().splitlines()\n",
    "# import libaries\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# string of all 26 characters sorted a to z. Works as all characters appear in training set.\n",
    "chars = sorted(list(set(''.join(train_set))))\n",
    "# mapping of characters to index.\n",
    "idx_to_char = {}\n",
    "char_to_idx = {}\n",
    "char_to_idx['.'] = 0\n",
    "for i,c in enumerate(chars):\n",
    "    char_to_idx[c] = i+1\n",
    "# create reverse mapping for use when plotting. \n",
    "idx_to_char = {i:c for c,i in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45881d69-17c2-4f56-b885-79a31df99600",
   "metadata": {},
   "source": [
    "### Supervised learning and network architecture\n",
    "\n",
    "We would like to learn the probabilities for our bigrams, given our dataset.\n",
    "That is, for a bigram `XY` within our dataset, we would like `P(X|Y)` to be high if this bigram occurs often, \n",
    "and low if it does not. \n",
    "We can treat the learning of these probabilities as a supervised learning task by creating pairs of inputs and outputs (labels)\n",
    "where the first half of each bigram is the input and the output is the second half.\n",
    "\n",
    "We'll use a simple, two layer network. \n",
    "The first layer will correspond to our bigram inputs and the second layer will represent our bigram probabilities. \n",
    "The two layers will be fully connected.But how do we present our bigram characters as input? \n",
    "\n",
    "Recall we have 27 characters within our alphabet. We can represent our inputs using a [one-hot encoding](https://en.wikipedia.org/wiki/One-hot#Machine_learning_and_statistics) vector.\n",
    "A one-hote vector is a vector that is all 0s except at the ith index which is one. \n",
    "This indicates that the vector represents the ith character in our language. \n",
    "\n",
    "As output for our model, recall we would like a probability distribution over all possible 27 characters that can end the bigram. \n",
    "In the previous notebook we normalized the occurrence counts by dividing each count by the sum of all counts. \n",
    "We can do something similar, but remember that the outputs of the second layer can be any real number (positive or negative.)\n",
    "To ensure we have a probability distribution, for each output we'll exponentiate it, the divide by the sum of all exponentiations. \n",
    "This will ensure that all outputs sum to one and is known as **softmax**.\n",
    "\n",
    "What's helpful is to think through the shape of our two layers. \n",
    "Suppose we had $n$ bigrams in our training data. \n",
    "We can stack these all together in a single $(n \\times 27)$ matrix. \n",
    "Since our two layers are fully connected and we'd like a probability for each bigram input, our second layer can be presented by a $(27 \\times 27)$ matrix, with the product of these two matrices being of size $(n \\times 27) (27 \\times 27) = (n \\times 27)$.\n",
    "This makes sense as each row of this matrix (the first character of the bigram) will have 27 values - each being a probability of what the following character of the bigram should be.\n",
    "\n",
    "Let's now begin by configuring our input and output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc8e3cf5-5f32-4624-9ef8-fd6ddb4b13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input/outputs\n",
    "X, Y = [], []\n",
    "for w in train_set:\n",
    "    chars = ['.']+list(w)+['.']\n",
    "    # use zip function to make every bigram in chars\n",
    "    for c1,c2 in zip(chars, chars[1:]):\n",
    "        idx0 = char_to_idx[c1]\n",
    "        idx1 = char_to_idx[c2]\n",
    "        X.append(idx0)\n",
    "        Y.append(idx1)\n",
    "# convert to tensors\n",
    "xs = torch.tensor(X)\n",
    "ys = torch.tensor(Y)\n",
    "n = xs.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d08cb933-b590-4bbe-b027-03ebaa9c71fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoding shape: torch.Size([204695, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24f1825c940>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use one-hot encoding to represent out inputs.\n",
    "import torch.nn.functional as F\n",
    "xencode = F.one_hot(xs, num_classes=27).float()\n",
    "print(\"Input encoding shape:\", xencode.shape)\n",
    "# plot one-hot encoding of some training data\n",
    "plt.imshow(xencode[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f1662e7-1495-4872-9a1c-150486621ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network \n",
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(892347120)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e365f-610d-434d-bf4b-ed4e63caec21",
   "metadata": {},
   "source": [
    "### Learning the probabilities\n",
    "\n",
    "For each input example we apply the one-hot vector to the matrix weights via multiplication to produce *logits*.\n",
    "We then exponentiate these values to convert them to probabilities.\n",
    "Our goal is to update $W$ to find which weight values produce probabilities that match our training data.\n",
    "But how do we do this? \n",
    "\n",
    "Recall in the last notebook we defined the average negative log-likelihood (NLL.) \n",
    "NLL is a differentiable function - by using it as our loss function and apply gradient descent, \n",
    "we are able to update the weights of $W$ at each step using a learning rate to minimize our lost. (Note a lot of this is handled by Pytorch via its computational graphs.)\n",
    "\n",
    "We iteratively perform this feed forward, calculate loss, then update weights until we've learned the correct weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a74f1ccd-1c27-4c72-af6c-a9d587857988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5182814598083496\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "xencode = F.one_hot(xs, num_classes=27).float()\n",
    "logits = xencode @ W # predict log-counts. '@' is used by torch to indicate matrix multiplication.\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "# compute average NLL\n",
    "loss = -probs[torch.arange(n), ys].log().mean()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59a79eeb-d1d7-43a1-b68b-be16d72b9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()\n",
    "# Update weights\n",
    "lr = 10 # learning rate\n",
    "W.data += -lr * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "001cbf07-bbcb-4155-a85a-7d29038c6314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8a579fa-7c8b-4204-86fe-a22340bb81c4",
   "metadata": {},
   "source": [
    "If we run the cells in order a few times, we'll see the loss printed decreases. Pulling it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2980017-8686-4924-99d1-c918f6d03539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network \n",
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(892347120)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6658fafb-1a4a-4e52-aa5f-ce36815a9a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1 loss: 3.7766432762145996\n",
      "i: 2 loss: 3.359241247177124\n",
      "i: 3 loss: 3.120978832244873\n",
      "i: 4 loss: 2.986562967300415\n",
      "i: 5 loss: 2.8932530879974365\n",
      "i: 6 loss: 2.824035167694092\n",
      "i: 7 loss: 2.771928071975708\n",
      "i: 8 loss: 2.732017993927002\n",
      "i: 9 loss: 2.700836420059204\n",
      "i: 10 loss: 2.6760060787200928\n",
      "i: 11 loss: 2.6558732986450195\n",
      "i: 12 loss: 2.639235496520996\n",
      "i: 13 loss: 2.625220537185669\n",
      "i: 14 loss: 2.613211154937744\n",
      "i: 15 loss: 2.6027727127075195\n",
      "i: 16 loss: 2.5935916900634766\n",
      "i: 17 loss: 2.585435390472412\n",
      "i: 18 loss: 2.578126907348633\n",
      "i: 19 loss: 2.571528911590576\n",
      "i: 20 loss: 2.565533399581909\n",
      "i: 21 loss: 2.560054302215576\n",
      "i: 22 loss: 2.5550224781036377\n",
      "i: 23 loss: 2.5503809452056885\n",
      "i: 24 loss: 2.546083450317383\n",
      "i: 25 loss: 2.542091131210327\n",
      "i: 26 loss: 2.5383706092834473\n",
      "i: 27 loss: 2.5348939895629883\n",
      "i: 28 loss: 2.5316381454467773\n",
      "i: 29 loss: 2.5285816192626953\n",
      "i: 30 loss: 2.5257058143615723\n",
      "i: 31 loss: 2.522996664047241\n",
      "i: 32 loss: 2.5204389095306396\n",
      "i: 33 loss: 2.5180206298828125\n",
      "i: 34 loss: 2.5157315731048584\n",
      "i: 35 loss: 2.5135607719421387\n",
      "i: 36 loss: 2.511500597000122\n",
      "i: 37 loss: 2.50954270362854\n",
      "i: 38 loss: 2.5076801776885986\n",
      "i: 39 loss: 2.505906820297241\n",
      "i: 40 loss: 2.504216432571411\n",
      "i: 41 loss: 2.502603530883789\n",
      "i: 42 loss: 2.501063823699951\n",
      "i: 43 loss: 2.4995920658111572\n",
      "i: 44 loss: 2.4981846809387207\n",
      "i: 45 loss: 2.496838092803955\n",
      "i: 46 loss: 2.4955480098724365\n",
      "i: 47 loss: 2.494311809539795\n",
      "i: 48 loss: 2.493126153945923\n",
      "i: 49 loss: 2.491987943649292\n",
      "i: 50 loss: 2.4908950328826904\n",
      "i: 51 loss: 2.489844799041748\n",
      "i: 52 loss: 2.488835334777832\n",
      "i: 53 loss: 2.4878640174865723\n",
      "i: 54 loss: 2.486928939819336\n",
      "i: 55 loss: 2.486027956008911\n",
      "i: 56 loss: 2.4851603507995605\n",
      "i: 57 loss: 2.4843239784240723\n",
      "i: 58 loss: 2.4835169315338135\n",
      "i: 59 loss: 2.4827382564544678\n",
      "i: 60 loss: 2.4819869995117188\n",
      "i: 61 loss: 2.4812607765197754\n",
      "i: 62 loss: 2.4805593490600586\n",
      "i: 63 loss: 2.4798812866210938\n",
      "i: 64 loss: 2.4792261123657227\n",
      "i: 65 loss: 2.4785923957824707\n",
      "i: 66 loss: 2.4779787063598633\n",
      "i: 67 loss: 2.4773850440979004\n",
      "i: 68 loss: 2.4768106937408447\n",
      "i: 69 loss: 2.4762539863586426\n",
      "i: 70 loss: 2.475714683532715\n",
      "i: 71 loss: 2.4751925468444824\n",
      "i: 72 loss: 2.4746861457824707\n",
      "i: 73 loss: 2.4741952419281006\n",
      "i: 74 loss: 2.473719358444214\n",
      "i: 75 loss: 2.473257541656494\n",
      "i: 76 loss: 2.4728095531463623\n",
      "i: 77 loss: 2.47237491607666\n",
      "i: 78 loss: 2.4719529151916504\n",
      "i: 79 loss: 2.471543073654175\n",
      "i: 80 loss: 2.4711451530456543\n",
      "i: 81 loss: 2.4707584381103516\n",
      "i: 82 loss: 2.4703831672668457\n",
      "i: 83 loss: 2.470018148422241\n",
      "i: 84 loss: 2.469663143157959\n",
      "i: 85 loss: 2.469318151473999\n",
      "i: 86 loss: 2.468982696533203\n",
      "i: 87 loss: 2.468656063079834\n",
      "i: 88 loss: 2.4683384895324707\n",
      "i: 89 loss: 2.468029499053955\n",
      "i: 90 loss: 2.467728614807129\n",
      "i: 91 loss: 2.467435598373413\n",
      "i: 92 loss: 2.4671499729156494\n",
      "i: 93 loss: 2.466872215270996\n",
      "i: 94 loss: 2.4666011333465576\n",
      "i: 95 loss: 2.466336965560913\n",
      "i: 96 loss: 2.4660794734954834\n",
      "i: 97 loss: 2.4658286571502686\n",
      "i: 98 loss: 2.465583562850952\n",
      "i: 99 loss: 2.4653446674346924\n",
      "i: 100 loss: 2.465111255645752\n",
      "i: 101 loss: 2.464883804321289\n",
      "i: 102 loss: 2.4646613597869873\n",
      "i: 103 loss: 2.464444160461426\n",
      "i: 104 loss: 2.4642322063446045\n",
      "i: 105 loss: 2.4640250205993652\n",
      "i: 106 loss: 2.463822364807129\n",
      "i: 107 loss: 2.4636242389678955\n",
      "i: 108 loss: 2.463430643081665\n",
      "i: 109 loss: 2.4632411003112793\n",
      "i: 110 loss: 2.4630556106567383\n",
      "i: 111 loss: 2.462874412536621\n",
      "i: 112 loss: 2.4626965522766113\n",
      "i: 113 loss: 2.4625229835510254\n",
      "i: 114 loss: 2.462352752685547\n",
      "i: 115 loss: 2.462186098098755\n",
      "i: 116 loss: 2.462022542953491\n",
      "i: 117 loss: 2.461862325668335\n",
      "i: 118 loss: 2.4617056846618652\n",
      "i: 119 loss: 2.4615519046783447\n",
      "i: 120 loss: 2.4614009857177734\n",
      "i: 121 loss: 2.4612531661987305\n",
      "i: 122 loss: 2.4611077308654785\n",
      "i: 123 loss: 2.460965633392334\n",
      "i: 124 loss: 2.4608256816864014\n",
      "i: 125 loss: 2.460688829421997\n",
      "i: 126 loss: 2.4605541229248047\n",
      "i: 127 loss: 2.4604218006134033\n",
      "i: 128 loss: 2.460292100906372\n",
      "i: 129 loss: 2.4601643085479736\n",
      "i: 130 loss: 2.4600393772125244\n",
      "i: 131 loss: 2.459916114807129\n",
      "i: 132 loss: 2.4597949981689453\n",
      "i: 133 loss: 2.4596762657165527\n",
      "i: 134 loss: 2.459559440612793\n",
      "i: 135 loss: 2.459444284439087\n",
      "i: 136 loss: 2.4593312740325928\n",
      "i: 137 loss: 2.4592201709747314\n",
      "i: 138 loss: 2.459110736846924\n",
      "i: 139 loss: 2.45900297164917\n",
      "i: 140 loss: 2.458897113800049\n",
      "i: 141 loss: 2.4587929248809814\n",
      "i: 142 loss: 2.458690643310547\n",
      "i: 143 loss: 2.458589553833008\n",
      "i: 144 loss: 2.4584903717041016\n",
      "i: 145 loss: 2.458392381668091\n",
      "i: 146 loss: 2.458296298980713\n",
      "i: 147 loss: 2.4582011699676514\n",
      "i: 148 loss: 2.4581077098846436\n",
      "i: 149 loss: 2.4580156803131104\n",
      "i: 150 loss: 2.457925319671631\n",
      "i: 151 loss: 2.4578356742858887\n",
      "i: 152 loss: 2.4577476978302\n",
      "i: 153 loss: 2.457660675048828\n",
      "i: 154 loss: 2.457575559616089\n",
      "i: 155 loss: 2.457491159439087\n",
      "i: 156 loss: 2.4574081897735596\n",
      "i: 157 loss: 2.4573261737823486\n",
      "i: 158 loss: 2.457245349884033\n",
      "i: 159 loss: 2.457165479660034\n",
      "i: 160 loss: 2.457087278366089\n",
      "i: 161 loss: 2.457009792327881\n",
      "i: 162 loss: 2.4569332599639893\n",
      "i: 163 loss: 2.456857681274414\n",
      "i: 164 loss: 2.4567835330963135\n",
      "i: 165 loss: 2.45671010017395\n",
      "i: 166 loss: 2.4566376209259033\n",
      "i: 167 loss: 2.456566095352173\n",
      "i: 168 loss: 2.456495523452759\n",
      "i: 169 loss: 2.4564261436462402\n",
      "i: 170 loss: 2.456357479095459\n",
      "i: 171 loss: 2.456289529800415\n",
      "i: 172 loss: 2.4562227725982666\n",
      "i: 173 loss: 2.4561567306518555\n",
      "i: 174 loss: 2.4560914039611816\n",
      "i: 175 loss: 2.456027030944824\n",
      "i: 176 loss: 2.455963134765625\n",
      "i: 177 loss: 2.4559004306793213\n",
      "i: 178 loss: 2.455838203430176\n",
      "i: 179 loss: 2.4557769298553467\n",
      "i: 180 loss: 2.455716371536255\n",
      "i: 181 loss: 2.4556565284729004\n",
      "i: 182 loss: 2.455597400665283\n",
      "i: 183 loss: 2.4555392265319824\n",
      "i: 184 loss: 2.4554812908172607\n",
      "i: 185 loss: 2.4554243087768555\n",
      "i: 186 loss: 2.4553682804107666\n",
      "i: 187 loss: 2.4553122520446777\n",
      "i: 188 loss: 2.4552571773529053\n",
      "i: 189 loss: 2.455203056335449\n",
      "i: 190 loss: 2.4551491737365723\n",
      "i: 191 loss: 2.4550962448120117\n",
      "i: 192 loss: 2.4550435543060303\n",
      "i: 193 loss: 2.4549918174743652\n",
      "i: 194 loss: 2.4549400806427\n",
      "i: 195 loss: 2.4548895359039307\n",
      "i: 196 loss: 2.4548394680023193\n",
      "i: 197 loss: 2.454789400100708\n",
      "i: 198 loss: 2.454740524291992\n",
      "i: 199 loss: 2.4546921253204346\n",
      "i: 200 loss: 2.454643726348877\n",
      "i: 201 loss: 2.4545962810516357\n",
      "i: 202 loss: 2.4545493125915527\n",
      "i: 203 loss: 2.454503059387207\n",
      "i: 204 loss: 2.4544572830200195\n",
      "i: 205 loss: 2.454411745071411\n",
      "i: 206 loss: 2.454366445541382\n",
      "i: 207 loss: 2.45432186126709\n",
      "i: 208 loss: 2.454277992248535\n",
      "i: 209 loss: 2.4542341232299805\n",
      "i: 210 loss: 2.454191207885742\n",
      "i: 211 loss: 2.454148530960083\n",
      "i: 212 loss: 2.454106092453003\n",
      "i: 213 loss: 2.4540646076202393\n",
      "i: 214 loss: 2.4540228843688965\n",
      "i: 215 loss: 2.453981876373291\n",
      "i: 216 loss: 2.453941583633423\n",
      "i: 217 loss: 2.453901529312134\n",
      "i: 218 loss: 2.4538614749908447\n",
      "i: 219 loss: 2.453822135925293\n",
      "i: 220 loss: 2.4537832736968994\n",
      "i: 221 loss: 2.453744649887085\n",
      "i: 222 loss: 2.4537065029144287\n",
      "i: 223 loss: 2.4536685943603516\n",
      "i: 224 loss: 2.4536314010620117\n",
      "i: 225 loss: 2.453594207763672\n",
      "i: 226 loss: 2.4535574913024902\n",
      "i: 227 loss: 2.4535210132598877\n",
      "i: 228 loss: 2.4534852504730225\n",
      "i: 229 loss: 2.4534494876861572\n",
      "i: 230 loss: 2.453413963317871\n",
      "i: 231 loss: 2.453378915786743\n",
      "i: 232 loss: 2.4533445835113525\n",
      "i: 233 loss: 2.453310012817383\n",
      "i: 234 loss: 2.4532761573791504\n",
      "i: 235 loss: 2.453242301940918\n",
      "i: 236 loss: 2.453209161758423\n",
      "i: 237 loss: 2.4531760215759277\n",
      "i: 238 loss: 2.4531431198120117\n",
      "i: 239 loss: 2.453110694885254\n",
      "i: 240 loss: 2.453078269958496\n",
      "i: 241 loss: 2.4530463218688965\n",
      "i: 242 loss: 2.453014850616455\n",
      "i: 243 loss: 2.4529836177825928\n",
      "i: 244 loss: 2.4529526233673096\n",
      "i: 245 loss: 2.4529221057891846\n",
      "i: 246 loss: 2.4528915882110596\n",
      "i: 247 loss: 2.4528613090515137\n",
      "i: 248 loss: 2.452831268310547\n",
      "i: 249 loss: 2.452801465988159\n",
      "i: 250 loss: 2.4527721405029297\n",
      "i: 251 loss: 2.4527430534362793\n",
      "i: 252 loss: 2.452713966369629\n",
      "i: 253 loss: 2.4526853561401367\n",
      "i: 254 loss: 2.4526569843292236\n",
      "i: 255 loss: 2.4526286125183105\n",
      "i: 256 loss: 2.4526007175445557\n",
      "i: 257 loss: 2.45257306098938\n",
      "i: 258 loss: 2.452545642852783\n",
      "i: 259 loss: 2.4525184631347656\n",
      "i: 260 loss: 2.452491283416748\n",
      "i: 261 loss: 2.4524645805358887\n",
      "i: 262 loss: 2.4524381160736084\n",
      "i: 263 loss: 2.4524118900299072\n",
      "i: 264 loss: 2.452385425567627\n",
      "i: 265 loss: 2.452359676361084\n",
      "i: 266 loss: 2.452333927154541\n",
      "i: 267 loss: 2.452308416366577\n",
      "i: 268 loss: 2.4522833824157715\n",
      "i: 269 loss: 2.452258348464966\n",
      "i: 270 loss: 2.45223331451416\n",
      "i: 271 loss: 2.4522085189819336\n",
      "i: 272 loss: 2.452183961868286\n",
      "i: 273 loss: 2.452159881591797\n",
      "i: 274 loss: 2.4521358013153076\n",
      "i: 275 loss: 2.4521119594573975\n",
      "i: 276 loss: 2.4520883560180664\n",
      "i: 277 loss: 2.452064275741577\n",
      "i: 278 loss: 2.4520411491394043\n",
      "i: 279 loss: 2.4520180225372314\n",
      "i: 280 loss: 2.4519951343536377\n",
      "i: 281 loss: 2.451972246170044\n",
      "i: 282 loss: 2.4519495964050293\n",
      "i: 283 loss: 2.4519271850585938\n",
      "i: 284 loss: 2.4519050121307373\n",
      "i: 285 loss: 2.451882839202881\n",
      "i: 286 loss: 2.4518609046936035\n",
      "i: 287 loss: 2.451838970184326\n",
      "i: 288 loss: 2.451817274093628\n",
      "i: 289 loss: 2.451796054840088\n",
      "i: 290 loss: 2.451774835586548\n",
      "i: 291 loss: 2.451753616333008\n",
      "i: 292 loss: 2.451732635498047\n",
      "i: 293 loss: 2.451711893081665\n",
      "i: 294 loss: 2.4516913890838623\n",
      "i: 295 loss: 2.4516706466674805\n",
      "i: 296 loss: 2.451650381088257\n",
      "i: 297 loss: 2.451630115509033\n",
      "i: 298 loss: 2.4516100883483887\n",
      "i: 299 loss: 2.451590061187744\n",
      "i: 300 loss: 2.451570510864258\n"
     ]
    }
   ],
   "source": [
    "iters = []\n",
    "losses = []\n",
    "lr = 50\n",
    "for i in range(300):\n",
    "    # forward pass\n",
    "    xencode = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = xencode @ W # predict log-counts. '@' is used by torch to indicate matrix multiplication.\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    # compute average NLL\n",
    "    loss = -probs[torch.arange(n), ys].log().mean()\n",
    "    print(f\"i: {i+1} loss: {loss.item()}\")\n",
    "    iters.append(i+1)\n",
    "    losses.append(loss.item())\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "    W.data += -lr * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c688302-df3f-4c23-85b3-785b3e9089fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24f226f0dc0>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets plot our loss per iteration below\n",
    "plt.plot(iters, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81328e26-6c82-41da-af00-defcb9c09c78",
   "metadata": {},
   "source": [
    "Finally, let's use this model to generate new names. \n",
    "Similar to last time, we start with our `.` character and use the probabilities to select the next character `x`, \n",
    "creating the bigram `.x`. We then sample the next character until we have our word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f218653-2d3a-489a-b785-739247051d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 'lli'. Name is in training set? False\n",
      "Name: 'ialindarie'. Name is in training set? False\n",
      "Name: 'lyamio'. Name is in training set? False\n",
      "Name: 'ripa'. Name is in training set? False\n",
      "Name: 'domanyay'. Name is in training set? False\n",
      "Name: 'erin'. Name is in training set? True\n",
      "Name: 'tietorlerle'. Name is in training set? False\n",
      "Name: 'dawiki'. Name is in training set? False\n",
      "Name: 'nirecondela'. Name is in training set? False\n",
      "Name: 'imean'. Name is in training set? False\n",
      "Name: 'mmiseryo'. Name is in training set? False\n",
      "Name: 'shrvalphala'. Name is in training set? False\n",
      "Name: 'clhatesoleelaynosi'. Name is in training set? False\n",
      "Name: 'kka'. Name is in training set? False\n",
      "Name: 'yqniavoma'. Name is in training set? False\n",
      "Name: 'ialeshyamietena'. Name is in training set? False\n",
      "Name: 'e'. Name is in training set? False\n",
      "Name: 'lesio'. Name is in training set? False\n",
      "Name: 'gay'. Name is in training set? True\n",
      "Name: 'sheiruiaeli'. Name is in training set? False\n"
     ]
    }
   ],
   "source": [
    "# Use a generator to sample character from a row.\n",
    "g = torch.Generator().manual_seed(892347120)\n",
    "# Sample 20 names from the model.\n",
    "for i in range(20):\n",
    "    out = []\n",
    "    # start in first row\n",
    "    idx = 0\n",
    "    while True:\n",
    "        xencode = F.one_hot(torch.tensor([idx]), num_classes=27).float()\n",
    "        logits = xencode @ W # predict log-counts. '@' is used by torch to indicate matrix multiplication.\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        probs = counts / counts.sum(1, keepdims=True)\n",
    "        idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item() \n",
    "        if idx == 0:\n",
    "            # idx value 0 (first column) is the stoping character .\n",
    "            break\n",
    "        out.append(idx_to_char[idx])\n",
    "    name = ''.join(out)\n",
    "    print(f\"Name: '{name}'. Name is in training set? {name in train_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36576aed-eb48-4670-b19f-8b3764572e19",
   "metadata": {},
   "source": [
    "Hmm, very similar to our previous occurrence count model!\n",
    "This is could be expected as the probabilities we're learning here are essentially the occurrence counts themselves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23fed8d-099b-45f3-9582-eb91638b9784",
   "metadata": {},
   "source": [
    "\n",
    "### Regularization\n",
    "\n",
    "Before finishing this notebook, we'll take a look at how we can tweak our loss function to fit our model to the training data better.\n",
    "Recall in the previous notebook some bigrams did not exist within our dataset. \n",
    "Instead of allowing for a zero probability for these bigrams, we added 1 to all of our occurrence counts which gave these bigrams a non-zero probability of occurring.   \n",
    "What would have happened if instead we added 1,000,000 to each bigram's occurrence count? \n",
    "The resulting distribution, while not exactly uniform, would be very close to it. \n",
    "\n",
    "By adding 1 to each occurrence count we **regularized** our model. \n",
    "We can do something similar to our neural net model by adding a term to our loss function changing it\n",
    "$$\n",
    "loss = NLL + \\lambda Regularization\n",
    "$$\n",
    "\n",
    "When $\\lambda = 0$ we have our NLL loss. \n",
    "Similar to how updating the occurrence counts changed our previous model's probabilities, we can use the $W$ matrix in our regularization to change the probabilities generated by our neural net. \n",
    "A common regularization term used is **L2 regularization** where L2 designates the L2 norm of the weight matrix.\n",
    "By adding a regularization term, our loss function needs to balance how it updates the weights of the matrix to minimize both the NLL and Regularization terms. \n",
    "\n",
    "We'll implement the regularization term below, as well seeing the names our model generates as it learns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95da75f2-4137-4beb-a279-4be1fad58345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 25 loss: 2.5531163215637207\n",
      "Name: 'mardia'. Name is in training set? False\n",
      "Name: 'aybb'. Name is in training set? False\n",
      "Name: 'aelriulnielah'. Name is in training set? False\n",
      "Name: 'aratieliadxray'. Name is in training set? False\n",
      "Name: 'vpdri'. Name is in training set? False\n",
      "Name: 'ja'. Name is in training set? True\n",
      "Name: 'kxjan'. Name is in training set? False\n",
      "Name: 'ken'. Name is in training set? True\n",
      "Name: 'mulista'. Name is in training set? False\n",
      "Name: 'h'. Name is in training set? False\n",
      "i: 50 loss: 2.504810333251953\n",
      "Name: 'kquzgpdro'. Name is in training set? False\n",
      "Name: 'siderioryjthnasqune'. Name is in training set? False\n",
      "Name: 'miata'. Name is in training set? False\n",
      "Name: 'ayla'. Name is in training set? True\n",
      "Name: 'ma'. Name is in training set? False\n",
      "Name: 'tko'. Name is in training set? False\n",
      "Name: 'lyn'. Name is in training set? True\n",
      "Name: 'm'. Name is in training set? False\n",
      "Name: 'kwygeman'. Name is in training set? False\n",
      "Name: 'phae'. Name is in training set? False\n",
      "i: 75 loss: 2.489291191101074\n",
      "Name: 'elerishcherionahx'. Name is in training set? False\n",
      "Name: 'cfiwnetarttone'. Name is in training set? False\n",
      "Name: 'd'. Name is in training set? False\n",
      "Name: 'en'. Name is in training set? False\n",
      "Name: 'cherusa'. Name is in training set? False\n",
      "Name: 'esilinapna'. Name is in training set? False\n",
      "Name: 'jidh'. Name is in training set? False\n",
      "Name: 'woa'. Name is in training set? False\n",
      "Name: 'brinara'. Name is in training set? False\n",
      "Name: 'kbamelal'. Name is in training set? False\n",
      "i: 100 loss: 2.4826889038085938\n",
      "Name: 'yane'. Name is in training set? False\n",
      "Name: 'kphernistelxrlh'. Name is in training set? False\n",
      "Name: 'ndessimcle'. Name is in training set? False\n",
      "Name: 'lo'. Name is in training set? True\n",
      "Name: 'xanzishe'. Name is in training set? False\n",
      "Name: 'jaeermahanerinneonilaneeeetayar'. Name is in training set? False\n",
      "Name: 'kiliynee'. Name is in training set? False\n",
      "Name: 'mvo'. Name is in training set? False\n",
      "Name: 'lyncierishila'. Name is in training set? False\n",
      "Name: 'narzima'. Name is in training set? False\n",
      "i: 125 loss: 2.4793803691864014\n",
      "Name: 'onerellich'. Name is in training set? False\n",
      "Name: 'camim'. Name is in training set? False\n",
      "Name: 'rer'. Name is in training set? False\n",
      "Name: 'ka'. Name is in training set? True\n",
      "Name: 'wnitureryass'. Name is in training set? False\n",
      "Name: 'rrad'. Name is in training set? False\n",
      "Name: 'ja'. Name is in training set? True\n",
      "Name: 'e'. Name is in training set? False\n",
      "Name: 'msatale'. Name is in training set? False\n",
      "Name: 'hayvoass'. Name is in training set? False\n",
      "i: 150 loss: 2.4774696826934814\n",
      "Name: 'kylvghulishilely'. Name is in training set? False\n",
      "Name: 'randanea'. Name is in training set? False\n",
      "Name: 'thar'. Name is in training set? False\n",
      "Name: 'belarxisiultongee'. Name is in training set? False\n",
      "Name: 'bele'. Name is in training set? False\n",
      "Name: 'sarlan'. Name is in training set? False\n",
      "Name: 'ma'. Name is in training set? False\n",
      "Name: 'dalai'. Name is in training set? False\n",
      "Name: 'sarahana'. Name is in training set? False\n",
      "Name: 's'. Name is in training set? False\n",
      "i: 175 loss: 2.47625732421875\n",
      "Name: 'jauda'. Name is in training set? False\n",
      "Name: 'ma'. Name is in training set? False\n",
      "Name: 'shi'. Name is in training set? True\n",
      "Name: 'ha'. Name is in training set? True\n",
      "Name: 'froritl'. Name is in training set? False\n",
      "Name: 'lein'. Name is in training set? False\n",
      "Name: 'shui'. Name is in training set? False\n",
      "Name: 'ror'. Name is in training set? False\n",
      "Name: 'ayrjuwexienzfoapvle'. Name is in training set? False\n",
      "Name: 'miaciliyrio'. Name is in training set? False\n",
      "i: 200 loss: 2.4754414558410645\n",
      "Name: 'acimiard'. Name is in training set? False\n",
      "Name: 'by'. Name is in training set? False\n",
      "Name: 'ra'. Name is in training set? False\n",
      "Name: 'je'. Name is in training set? False\n",
      "Name: 're'. Name is in training set? False\n",
      "Name: 'meeiriyasadiy'. Name is in training set? False\n",
      "Name: 'wyalid'. Name is in training set? False\n",
      "Name: 'derikii'. Name is in training set? False\n",
      "Name: 'jarod'. Name is in training set? True\n",
      "Name: 'hashiphialyn'. Name is in training set? False\n",
      "i: 225 loss: 2.4748685359954834\n",
      "Name: 'sph'. Name is in training set? False\n",
      "Name: 'thandan'. Name is in training set? False\n",
      "Name: 'esh'. Name is in training set? False\n",
      "Name: 's'. Name is in training set? False\n",
      "Name: 'oron'. Name is in training set? False\n",
      "Name: 'danchyaimixydindedia'. Name is in training set? False\n",
      "Name: 'jantena'. Name is in training set? False\n",
      "Name: 'shwahattharojeryarco'. Name is in training set? False\n",
      "Name: 'ttacioliquaikaniol'. Name is in training set? False\n",
      "Name: 'ghalude'. Name is in training set? False\n",
      "i: 250 loss: 2.4744532108306885\n",
      "Name: 'shaly'. Name is in training set? False\n",
      "Name: 'araee'. Name is in training set? False\n",
      "Name: 'pa'. Name is in training set? True\n",
      "Name: 'ma'. Name is in training set? False\n",
      "Name: 'ttorila'. Name is in training set? False\n",
      "Name: 'shen'. Name is in training set? False\n",
      "Name: 'ch'. Name is in training set? False\n",
      "Name: 'iliougada'. Name is in training set? False\n",
      "Name: 'adan'. Name is in training set? True\n",
      "Name: 'kalle'. Name is in training set? True\n",
      "i: 275 loss: 2.4741437435150146\n",
      "Name: 'rie'. Name is in training set? False\n",
      "Name: 'ri'. Name is in training set? False\n",
      "Name: 'thph'. Name is in training set? False\n",
      "Name: 'rri'. Name is in training set? False\n",
      "Name: 'yll'. Name is in training set? False\n",
      "Name: 'ca'. Name is in training set? False\n",
      "Name: 's'. Name is in training set? False\n",
      "Name: 's'. Name is in training set? False\n",
      "Name: 'ty'. Name is in training set? True\n",
      "Name: 'fry'. Name is in training set? False\n",
      "i: 300 loss: 2.4739081859588623\n",
      "Name: 'ga'. Name is in training set? False\n",
      "Name: 'mallyar'. Name is in training set? False\n",
      "Name: 'ja'. Name is in training set? True\n",
      "Name: 'gearausicuenckilevoh'. Name is in training set? False\n",
      "Name: 'y'. Name is in training set? False\n",
      "Name: 'derori'. Name is in training set? False\n",
      "Name: 'rity'. Name is in training set? False\n",
      "Name: 'sa'. Name is in training set? False\n",
      "Name: 'jerigiunalel'. Name is in training set? False\n",
      "Name: 'o'. Name is in training set? False\n",
      "i: 325 loss: 2.4737253189086914\n",
      "Name: 'cis'. Name is in training set? False\n",
      "Name: 'chuin'. Name is in training set? False\n",
      "Name: 's'. Name is in training set? False\n",
      "Name: 'jouoller'. Name is in training set? False\n",
      "Name: 'te'. Name is in training set? False\n",
      "Name: 'skuinshimaha'. Name is in training set? False\n",
      "Name: 'jionin'. Name is in training set? False\n",
      "Name: 'li'. Name is in training set? True\n",
      "Name: 'anigjarorth'. Name is in training set? False\n",
      "Name: 'yny'. Name is in training set? False\n",
      "i: 350 loss: 2.473581314086914\n",
      "Name: 'jaenissam'. Name is in training set? False\n",
      "Name: 'a'. Name is in training set? False\n",
      "Name: 'sha'. Name is in training set? True\n",
      "Name: ''. Name is in training set? False\n",
      "Name: 'sa'. Name is in training set? False\n",
      "Name: 'n'. Name is in training set? False\n",
      "Name: 'cekashadelulya'. Name is in training set? False\n",
      "Name: 'ama'. Name is in training set? False\n",
      "Name: 'shyludo'. Name is in training set? False\n",
      "Name: 'zagee'. Name is in training set? False\n",
      "i: 375 loss: 2.473466157913208\n",
      "Name: 'rle'. Name is in training set? False\n",
      "Name: 'chireeidyawel'. Name is in training set? False\n",
      "Name: 'zjelianana'. Name is in training set? False\n",
      "Name: 'dinosta'. Name is in training set? False\n",
      "Name: 'kbaittie'. Name is in training set? False\n",
      "Name: 'ma'. Name is in training set? False\n",
      "Name: 'ttetra'. Name is in training set? False\n",
      "Name: 'bte'. Name is in training set? False\n",
      "Name: 'junas'. Name is in training set? False\n",
      "Name: 'fe'. Name is in training set? False\n",
      "i: 400 loss: 2.4733731746673584\n",
      "Name: 'hemeluvieniaiben'. Name is in training set? False\n",
      "Name: 'vininichuquburladonntia'. Name is in training set? False\n",
      "Name: 'cetlynusha'. Name is in training set? False\n",
      "Name: 'chalihen'. Name is in training set? False\n",
      "Name: 'ghanien'. Name is in training set? False\n",
      "Name: 'eshaiauja'. Name is in training set? False\n",
      "Name: 'maya'. Name is in training set? True\n",
      "Name: 't'. Name is in training set? False\n",
      "Name: 'g'. Name is in training set? False\n",
      "Name: 'jephavoly'. Name is in training set? False\n",
      "i: 425 loss: 2.473296880722046\n",
      "Name: 'akan'. Name is in training set? False\n",
      "Name: 'latishana'. Name is in training set? False\n",
      "Name: 'le'. Name is in training set? True\n",
      "Name: 'tenenitarioen'. Name is in training set? False\n",
      "Name: 's'. Name is in training set? False\n",
      "Name: 'cfat'. Name is in training set? False\n",
      "Name: 'h'. Name is in training set? False\n",
      "Name: 'nz'. Name is in training set? False\n",
      "Name: 'degiareemesakal'. Name is in training set? False\n",
      "Name: 'agoron'. Name is in training set? False\n",
      "i: 450 loss: 2.473233938217163\n",
      "Name: 'becamonan'. Name is in training set? False\n",
      "Name: 'jalilel'. Name is in training set? False\n",
      "Name: 'morika'. Name is in training set? False\n",
      "Name: 'jes'. Name is in training set? False\n",
      "Name: 'bresanenete'. Name is in training set? False\n",
      "Name: 'nereriannd'. Name is in training set? False\n",
      "Name: 'deriana'. Name is in training set? False\n",
      "Name: 'del'. Name is in training set? True\n",
      "Name: 'ar'. Name is in training set? False\n",
      "Name: 'nwinpr'. Name is in training set? False\n",
      "i: 475 loss: 2.47318172454834\n",
      "Name: 'ryai'. Name is in training set? False\n",
      "Name: 'lllolg'. Name is in training set? False\n",
      "Name: 'ablayairilyeitiayapuph'. Name is in training set? False\n",
      "Name: 'n'. Name is in training set? False\n",
      "Name: 'thariatel'. Name is in training set? False\n",
      "Name: 'zmanin'. Name is in training set? False\n",
      "Name: 'h'. Name is in training set? False\n",
      "Name: 'sstema'. Name is in training set? False\n",
      "Name: 'ba'. Name is in training set? False\n",
      "Name: 'mya'. Name is in training set? True\n",
      "i: 500 loss: 2.473137855529785\n",
      "Name: 'mat'. Name is in training set? True\n",
      "Name: 'meericotan'. Name is in training set? False\n",
      "Name: 'juele'. Name is in training set? False\n",
      "Name: 'man'. Name is in training set? True\n",
      "Name: 'li'. Name is in training set? True\n",
      "Name: 'ahanabieli'. Name is in training set? False\n",
      "Name: 'n'. Name is in training set? False\n",
      "Name: 'ruprmamon'. Name is in training set? False\n",
      "Name: 'elayel'. Name is in training set? False\n",
      "Name: 'me'. Name is in training set? False\n"
     ]
    }
   ],
   "source": [
    "# Define network \n",
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(892347120)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "iters = []\n",
    "losses = []\n",
    "lr = 50\n",
    "for i in range(500):\n",
    "    # forward pass\n",
    "    xencode = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = xencode @ W # predict log-counts. '@' is used by torch to indicate matrix multiplication.\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    # compute average NLL w/ regularization\n",
    "    loss = -probs[torch.arange(n), ys].log().mean() + 0.01*(W**2).mean()\n",
    "    if ((i+1) % 25) == 0:\n",
    "        print(f\"i: {i+1} loss: {loss.item()}\")\n",
    "        for j in range(10):\n",
    "            out = []\n",
    "            # start in first row\n",
    "            idx = 0\n",
    "            while True:\n",
    "                xencode = F.one_hot(torch.tensor([idx]), num_classes=27).float()\n",
    "                logits = xencode @ W # predict log-counts. '@' is used by torch to indicate matrix multiplication.\n",
    "                counts = logits.exp() # counts, equivalent to N\n",
    "                probs = counts / counts.sum(1, keepdims=True)\n",
    "                idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item() \n",
    "                if idx == 0:\n",
    "                    # idx value 0 (first column) is the stoping character .\n",
    "                    break\n",
    "                out.append(idx_to_char[idx])\n",
    "            name = ''.join(out)\n",
    "            print(f\"Name: '{name}'. Name is in training set? {name in train_set}\")\n",
    "    iters.append(i+1)\n",
    "    losses.append(loss.item())\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "    W.data += -lr * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1e3bb0b8-e0e3-4bb5-9ac2-b074e66baaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24f2280b730>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b93b8-988e-40fa-9bc3-ca37d6a5ebba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
